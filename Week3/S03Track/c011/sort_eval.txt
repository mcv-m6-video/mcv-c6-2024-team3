Error importing BURST due to missing underlying dependency: No module named 'pycocotools'

Eval Config:
USE_PARALLEL         : False                         
NUM_PARALLEL_CORES   : 1                             
BREAK_ON_ERROR       : True                          
RETURN_ON_ERROR      : False                         
LOG_ON_ERROR         : /mnt/d/GithubProject/mcv-c6-2024-team3/Week3/TrackEval/error_log.txt
PRINT_RESULTS        : True                          
PRINT_ONLY_COMBINED  : False                         
PRINT_CONFIG         : True                          
TIME_PROGRESS        : True                          
DISPLAY_LESS_PROGRESS : False                         
OUTPUT_SUMMARY       : True                          
OUTPUT_EMPTY_CLASSES : True                          
OUTPUT_DETAILED      : True                          
PLOT_CURVES          : True                          

MotChallenge2DBox Config:
PRINT_CONFIG         : True                          
GT_FOLDER            : /mnt/d/GithubProject/mcv-c6-2024-team3/Week3/TrackEval/data/gt/mot_challenge/
TRACKERS_FOLDER      : /mnt/d/GithubProject/mcv-c6-2024-team3/Week3/TrackEval/data/trackers/mot_challenge/
OUTPUT_FOLDER        : None                          
TRACKERS_TO_EVAL     : ['PerfectTracker']            
CLASSES_TO_EVAL      : ['pedestrian']                
BENCHMARK            : custom                        
SPLIT_TO_EVAL        : train                         
INPUT_AS_ZIP         : False                         
DO_PREPROC           : False                         
TRACKER_SUB_FOLDER   : data                          
OUTPUT_SUB_FOLDER    :                               
TRACKER_DISPLAY_NAMES : None                          
SEQMAP_FOLDER        : None                          
SEQMAP_FILE          : None                          
SEQ_INFO             : None                          
GT_LOC_FORMAT        : {gt_folder}/{seq}/gt/gt.txt   
SKIP_SPLIT_FOL       : False                         

Identity Config:
METRICS              : ['HOTA', 'Identity']          
THRESHOLD            : 0.5                           
PRINT_CONFIG         : True                          

Evaluating 1 tracker(s) on 1 sequence(s) for 1 class(es) on MotChallenge2DBox dataset using the following metrics: HOTA, Identity, Count


Evaluating PerfectTracker

    MotChallenge2DBox.get_raw_seq_data(PerfectTracker, custom-01)          0.1997 sec
    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.2087 sec
    HOTA.eval_sequence()                                                   0.1682 sec
    Identity.eval_sequence()                                               0.0177 sec
    Count.eval_sequence()                                                  0.0000 sec
1 eval_sequence(custom-01, PerfectTracker)                               0.6016 sec

All sequences for PerfectTracker finished in 0.60 seconds

HOTA: PerfectTracker-pedestrian    HOTA      DetA      AssA      DetRe     DetPr     AssRe     AssPr     LocA      OWTA      HOTA(0)   LocA(0)   HOTALocA(0)
custom-01                          11.429    3.5778    38.857    52.509    3.6514    60.19     57.812    73.678    43.848    16.573    62.669    10.386    
COMBINED                           11.429    3.5778    38.857    52.509    3.6514    60.19     57.812    73.678    43.848    16.573    62.669    10.386    

Identity: PerfectTracker-pedestrianIDF1      IDR       IDP       IDTP      IDFN      IDFP      
custom-01                          7.7096    59.288    4.1228    533       366       12395     
COMBINED                           7.7096    59.288    4.1228    533       366       12395     

Count: PerfectTracker-pedestrian   Dets      GT_Dets   IDs       GT_IDs    
custom-01                          12928     899       144       17        
COMBINED                           12928     899       144       17        

Timing analysis:
MotChallenge2DBox.get_raw_seq_data                                     0.1997 sec
MotChallenge2DBox.get_preprocessed_seq_data                            0.2087 sec
HOTA.eval_sequence                                                     0.1682 sec
Identity.eval_sequence                                                 0.0177 sec
Count.eval_sequence                                                    0.0000 sec
eval_sequence                                                          0.6016 sec
Evaluator.evaluate                                                     2.8693 sec
